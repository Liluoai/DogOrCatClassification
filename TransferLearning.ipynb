{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导出特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.applications.resnet50 import ResNet50, decode_predictions\n",
    "from keras.applications import *\n",
    "import cv2, os, itertools\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train/'\n",
    "TEST_DIR = 'data/test/'\n",
    "\n",
    "train_dir = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR)]\n",
    "# train_dog_dir = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "# train_cat_dir = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "test_dir = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "# train_dir = train_dir[:50]\n",
    "# test_dir = test_dir[:50]\n",
    "train_dir.sort()\n",
    "test_dir.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save feature vector to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "concat_train_feature_vector = np.ndarray((len(train_dir), 2048 + 2048 + 512 + 512), dtype = np.float32)\n",
    "concat_test_feature_vector = np.ndarray((len(test_dir), 2048 + 2048 + 512 + 512), dtype = np.float32)\n",
    "\n",
    "def get_feature_vector_list(image_path_list, MODEL, input_size, preprocess_fun = None):\n",
    "    inputs = Input(input_size)\n",
    "    #注意: 预处理函数对于Xception和InceptionV3都是必须的, 否则会预测出错\n",
    "    if preprocess_fun:\n",
    "        inputs = Lambda(preprocess_fun)(inputs)\n",
    "        \n",
    "    #❓我的组合模型为什么错了\n",
    "#     x = MODEL(input_tensor = inputs, include_top = False).output\n",
    "#     outputs = GlobalAveragePooling2D()(x)\n",
    "#     model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "    #别人的正确模型\n",
    "    base_model = MODEL(input_tensor = inputs, weights = 'imagenet', include_top = False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    #不修改的模型\n",
    "#     model = MODEL(input_tensor = inputs, weights='imagenet')\n",
    "\n",
    "    print('start {} prediction:'.format(base_model.name))\n",
    "    feature_vector_list = []\n",
    "    for i, image_path in enumerate(image_path_list):\n",
    "        input_image = prepare_data(image_path, input_size)\n",
    "        input_image = np.expand_dims(input_image, axis = 0)\n",
    "        feature_vector = model.predict(input_image, verbose = 0)\n",
    "        feature_vector_list.append(feature_vector)\n",
    "        #显示进度条\n",
    "        if i%(len(image_path_list)//100) == 0:\n",
    "            print('>', end = '')\n",
    "    print('finish {} prediction'.format(base_model.name))\n",
    "    \n",
    "    return feature_vector_list\n",
    "\n",
    "        \n",
    "def prepare_data(image_path, input_size):\n",
    "    rows = input_size[0]\n",
    "    cols = input_size[1]\n",
    "    channels = input_size[2]\n",
    "    data = np.ndarray(input_size, dtype = np.uint8)\n",
    "    \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (rows, cols), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def get_and_save_feature_vector():\n",
    "    #ResNet50输出(1, 2048)\n",
    "    ResNet50_train_feature_vector_list = get_feature_vector_list(train_dir, ResNet50, (224, 224, 3))\n",
    "    #Xception输出(1, 2048)\n",
    "    Xception_train_feature_vector_list = get_feature_vector_list(train_dir, Xception, (299, 299, 3), xception.preprocess_input)\n",
    "    #TODO: 修正InceptionV3模型的错误使用\n",
    "    # get_feature_vector(image_path, InceptionV3, (299, 299, 3), inception_v3.preprocess_input)\n",
    "    #VGG16输出(1, 512)\n",
    "    VGG16_train_feature_vector_list = get_feature_vector_list(train_dir, VGG16, (224, 224, 3))\n",
    "    #VGG19输出(1, 512)\n",
    "    VGG19_train_feature_vector_list = get_feature_vector_list(train_dir, VGG19, (224, 224, 3))\n",
    "    for i in range(len(train_dir)):\n",
    "        concat_train_feature_vector[i] = np.concatenate([ResNet50_train_feature_vector_list[i], \n",
    "                                                        Xception_train_feature_vector_list[i],\n",
    "                                                        VGG16_train_feature_vector_list[i],\n",
    "                                                        VGG19_train_feature_vector_list[i]], axis=1)\n",
    "    \n",
    "    ResNet50_test_feature_vector_list = get_feature_vector_list(test_dir, ResNet50, (224, 224, 3))\n",
    "    Xception_test_feature_vector_list = get_feature_vector_list(test_dir, Xception, (299, 299, 3), xception.preprocess_input)\n",
    "    VGG16_test_feature_vector_list = get_feature_vector_list(test_dir, VGG16, (224, 224, 3))\n",
    "    VGG19_test_feature_vector_list = get_feature_vector_list(test_dir, VGG19, (224, 224, 3))\n",
    "    for i in range(len(test_dir)):\n",
    "        concat_test_feature_vector[i] = np.concatenate([ResNet50_test_feature_vector_list[i], \n",
    "                                                        Xception_test_feature_vector_list[i],\n",
    "                                                        VGG16_test_feature_vector_list[i],\n",
    "                                                        VGG19_test_feature_vector_list[i]], axis=1)\n",
    "    \n",
    "    np.savetxt(\"concat_train_feature_vector.npy\", concat_train_feature_vector, delimiter = ',')\n",
    "    np.savetxt(\"concat_test_feature_vector.npy\", concat_test_feature_vector, delimiter = ',')\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "get_and_save_feature_vector() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read feature vector from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test_feature_vector = np.loadtxt(open(\"concat_test_feature_vector.npy\",\"rb\"), delimiter=\",\").astype(np.float32)\n",
    "concat_train_feature_vector = np.loadtxt(open(\"concat_train_feature_vector.npy\",\"rb\"), delimiter=\",\").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_test_feature_vector2 = concat_test_feature_vector[:, :4096]\n",
    "concat_train_feature_vector2 = concat_train_feature_vector[:, :4096]\n",
    "concat_train_feature_vector2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "labels = []\n",
    "for train_image_dir in train_dir[:10]:\n",
    "    if 'dog' in train_image_dir:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "        \n",
    "y_train = np.array(labels)\n",
    "x_train, y_train = shuffle(concat_train_feature_vector, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (x_train.shape[1], ))\n",
    "x = Dropout(0.5)(inputs)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs = inputs, outputs = predictions)\n",
    "model.compile(optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)\n",
    "y_pre = model.predict(concat_test_feature_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

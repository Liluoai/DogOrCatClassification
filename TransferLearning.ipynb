{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导出特征向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, GlobalAveragePooling2D\n",
    "from keras.applications.resnet50 import ResNet50, decode_predictions\n",
    "from keras.applications import *\n",
    "import cv2, os, itertools\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'data/train/'\n",
    "TEST_DIR = 'data/test/'\n",
    "\n",
    "train_dir = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR)]\n",
    "train_dog_dir = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\n",
    "train_cat_dir = [TRAIN_DIR + i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n",
    "test_dir = [TEST_DIR + i for i in os.listdir(TEST_DIR)]\n",
    "\n",
    "# train_dir = train_dir[:50]\n",
    "# test_dir = test_dir[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save feature vector to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start resnet50 prediction:\n",
      ">>>>>>>>>>>>"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "concat_train_feature_vector = np.ndarray((len(train_dir), 2048 + 2048 + 512 + 512), dtype = np.float32)\n",
    "concat_test_feature_vector = np.ndarray((len(test_dir), 2048 + 2048 + 512 + 512), dtype = np.float32)\n",
    "\n",
    "def get_feature_vector_list(image_path_list, MODEL, input_size, preprocess_fun = None):\n",
    "    inputs = Input(input_size)\n",
    "    #注意: 预处理函数对于Xception和InceptionV3都是必须的, 否则会预测出错\n",
    "    if preprocess_fun:\n",
    "        inputs = Lambda(preprocess_fun)(inputs)\n",
    "        \n",
    "    #❓我的组合模型为什么错了\n",
    "#     x = MODEL(input_tensor = inputs, include_top = False).output\n",
    "#     outputs = GlobalAveragePooling2D()(x)\n",
    "#     model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "    #别人的正确模型\n",
    "    base_model = MODEL(input_tensor = inputs, weights = 'imagenet', include_top = False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    #不修改的模型\n",
    "#     model = MODEL(input_tensor = inputs, weights='imagenet')\n",
    "\n",
    "    print('start {} prediction:'.format(base_model.name))\n",
    "    feature_vector_list = []\n",
    "    for i, image_path in enumerate(image_path_list):\n",
    "        input_image = prepare_data(image_path, input_size)\n",
    "        input_image = np.expand_dims(input_image, axis = 0)\n",
    "        feature_vector = model.predict(input_image, verbose = 0)\n",
    "        feature_vector_list.append(feature_vector)\n",
    "        #显示进度条\n",
    "        if i%(len(image_path_list)//100) == 0:\n",
    "            print('>', end = '')\n",
    "    print('finish {} prediction'.format(base_model.name))\n",
    "    \n",
    "    return feature_vector_list\n",
    "\n",
    "        \n",
    "def prepare_data(image_path, input_size):\n",
    "    rows = input_size[0]\n",
    "    cols = input_size[1]\n",
    "    channels = input_size[2]\n",
    "    data = np.ndarray(input_size, dtype = np.uint8)\n",
    "    \n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image = cv2.resize(image, (rows, cols), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def get_and_save_feature_vector():\n",
    "    #ResNet50输出(1, 2048)\n",
    "    ResNet50_train_feature_vector_list = get_feature_vector_list(train_dir, ResNet50, (224, 224, 3))\n",
    "    #Xception输出(1, 2048)\n",
    "    Xception_train_feature_vector_list = get_feature_vector_list(train_dir, Xception, (299, 299, 3), xception.preprocess_input)\n",
    "    #TODO: 修正InceptionV3模型的错误使用\n",
    "    # get_feature_vector(image_path, InceptionV3, (299, 299, 3), inception_v3.preprocess_input)\n",
    "    #VGG16输出(1, 512)\n",
    "    VGG16__train_feature_vector_list = get_feature_vector_list(train_dir, VGG16, (224, 224, 3))\n",
    "    #VGG19输出(1, 512)\n",
    "    VGG19__train_feature_vector_list = get_feature_vector_list(train_dir, VGG19, (224, 224, 3))\n",
    "    for i in range(len(train_dir)):\n",
    "        concat_train_feature_vector[i] = np.concatenate([ResNet50_train_feature_vector_list[i], \n",
    "                                                        Xception_train_feature_vector_list[i],\n",
    "                                                        VGG16__train_feature_vector_list[i],\n",
    "                                                        VGG19__train_feature_vector_list[i]], axis=1)\n",
    "    \n",
    "    ResNet50_test_feature_vector_list = get_feature_vector_list(test_dir, ResNet50, (224, 224, 3))\n",
    "    Xception_test_feature_vector_list = get_feature_vector_list(test_dir, Xception, (299, 299, 3), xception.preprocess_input)\n",
    "    VGG16__test_feature_vector_list = get_feature_vector_list(test_dir, VGG16, (224, 224, 3))\n",
    "    VGG19__test_feature_vector_list = get_feature_vector_list(test_dir, VGG19, (224, 224, 3))\n",
    "    for i in range(len(test_dir)):\n",
    "        concat_test_feature_vector[i] = np.concatenate([ResNet50_test_feature_vector_list[i], \n",
    "                                                        Xception_test_feature_vector_list[i],\n",
    "                                                        VGG16__test_feature_vector_list[i],\n",
    "                                                        VGG19__test_feature_vector_list[i]], axis=1)\n",
    "    \n",
    "    np.savetxt(\"concat_train_feature_vector.npy\", concat_train_feature_vector, delimiter = ',')\n",
    "    np.savetxt(\"concat_test_feature_vector.npy\", concat_test_feature_vector, delimiter = ',')\n",
    "        \n",
    "    return None\n",
    "\n",
    "\n",
    "get_and_save_feature_vector() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33034202"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_concat_test_feature_vector = np.loadtxt(open(\"concat_test_feature_vector.npy\",\"rb\"), delimiter=\",\").astype(np.float32)\n",
    "read_concat_test_feature_vector[40][2331]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_image shape before: (224, 224, 3)\n",
      "input_image shape after: (1, 224, 224, 3)\n",
      "1/1 [==============================] - 1s\n",
      "train_feature shape: (1, 2048)\n",
      "train_feature shape: <class 'numpy.float32'>\n",
      "train_feature vector: [[ 0.04036946  0.26829532  0.29243729 ...,  0.          0.26024085\n",
      "   0.83237869]]\n"
     ]
    }
   ],
   "source": [
    "MODEL = VGG16\n",
    "input_size = (224, 224, 3)\n",
    "preprocess_fun = None\n",
    "\n",
    "inputs = Input(input_size)\n",
    "if preprocess_fun:\n",
    "    inputs = Lambda(preprocess_fun)(inputs)\n",
    "        \n",
    "# x = MODEL(input_tensor = inputs, include_top = False).output\n",
    "# outputs = GlobalAveragePooling2D()(x)\n",
    "# model = Model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "base_model = MODEL(input_tensor = inputs, weights = 'imagenet', include_top = False)\n",
    "model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# model = MODEL(input_tensor = inputs)\n",
    "# print(%MODEL.func_name)\n",
    "\n",
    "        \n",
    "image_path = 'data/train/cat.2.jpg'\n",
    "input_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "input_image = cv2.resize(input_image, (input_size[0], input_size[1]), interpolation = cv2.INTER_CUBIC)\n",
    "print('input_image shape before: {}'.format(input_image.shape))\n",
    "input_image = np.expand_dims(input_image, axis = 0)\n",
    "print('input_image shape after: {}'.format(input_image.shape))\n",
    "train_feature = model.predict(input_image, verbose = 1)\n",
    "print('train_feature shape: {}'.format(train_feature.shape))\n",
    "print('train_feature shape: {}'.format(type(train_feature[0][1])))\n",
    "print('train_feature vector: {}'.format(train_feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dog-project",
   "language": "python",
   "name": "dog-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
